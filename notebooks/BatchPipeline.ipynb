{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3e1445fc-04f0-4c52-b988-343e771bb67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkConf\n",
    "from pyspark.sql.functions import col, sum as _sum, dense_rank, round as _round\n",
    "from pyspark.sql.window import Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "120124b8-da2e-4a53-b368-75a7fa659461",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spark Configuration\n",
    "sparkConf = SparkConf()\n",
    "sparkConf.setMaster(\"spark://spark-master:7077\")\n",
    "sparkConf.setAppName(\"Best_Selling_Products_Pipeline\")\n",
    "sparkConf.set(\"spark.driver.memory\", \"2g\")\n",
    "sparkConf.set(\"spark.executor.cores\", \"1\")\n",
    "sparkConf.set(\"spark.driver.cores\", \"1\")\n",
    "spark = SparkSession.builder.config(conf=sparkConf).getOrCreate()\n",
    "\n",
    "# Setup hadoop fs configuration for schema gs://\n",
    "conf = spark.sparkContext._jsc.hadoopConfiguration()\n",
    "conf.set(\"fs.gs.impl\", \"com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystem\")\n",
    "conf.set(\"fs.AbstractFileSystem.gs.impl\", \"com.google.cloud.hadoop.fs.gcs.GoogleHadoopFS\")\n",
    "\n",
    "data_bucket_uri = \"data_de2024_a2\"\n",
    "temp_bucket = \"temp_de2024_mh\"\n",
    "project_id = \"core-synthesis-435410-v9\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "08a31251-b4ba-4a4f-8ebd-dcab33eb9986",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Fact and Dimension Tables\n",
    "factDF = spark.read.format(\"csv\").option(\"header\", \"true\").load(f\"gs://{data_bucket_uri}/fact_table.csv\")\n",
    "itemDF = spark.read.format(\"csv\").option(\"header\", \"true\").load(f\"gs://{data_bucket_uri}/item_dim.csv\")\n",
    "storeDF = spark.read.format(\"csv\").option(\"header\", \"true\").load(f\"gs://{data_bucket_uri}/store_dim.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411aa8e5-4caf-41fa-836f-24da3628719f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+--------------------+-------------+------------+---------------------+--------------+\n",
      "|store_key|item_key|           item_name|product_sales|product_rank|top_store_total_sales|top_store_rank|\n",
      "+---------+--------+--------------------+-------------+------------+---------------------+--------------+\n",
      "|    S0010|  I00119|K Cups Original D...|       3021.0|           1|             159409.0|             1|\n",
      "|    S0010|  I00123|     Honey Packets  |       2565.0|           2|             159409.0|             1|\n",
      "|    S0010|  I00061|       Red Bull 12oz|       2255.0|           3|             159409.0|             1|\n",
      "|    S0010|  I00177|M&M Peanut Candy ...|       2240.0|           4|             159409.0|             1|\n",
      "|    S0010|  I00054|Monster Zero Ultr...|       2160.0|           5|             159409.0|             1|\n",
      "|    S0010|  I00183| Snickers Bars 1.8oz|       1890.0|           6|             159409.0|             1|\n",
      "|    S0010|  I00140|Foam Coffee Cups ...|       1885.0|           7|             159409.0|             1|\n",
      "|    S0010|  I00117|K Cups Folgers Li...|       1840.0|           8|             159409.0|             1|\n",
      "|    S0010|  I00253|ForceFlex Trash B...|       1596.0|           9|             159409.0|             1|\n",
      "|    S0010|  I00059|Muscle Milk Prote...|       1584.0|          10|             159409.0|             1|\n",
      "|    S0010|  I00118|K Cups �Organic B...|       1554.0|          11|             159409.0|             1|\n",
      "|    S0010|  I00114|K Cups � Starbuck...|       1540.0|          12|             159409.0|             1|\n",
      "|    S0010|  I00261|POM 2 ply paper t...|       1518.0|          13|             159409.0|             1|\n",
      "|    S0010|  I00058|Premier Protein S...|       1474.0|          14|             159409.0|             1|\n",
      "|    S0010|  I00257|Large Trash Bags ...|       1407.0|          15|             159409.0|             1|\n",
      "|    S0010|  I00052|Monster Lo-Carb 1...|       1400.0|          16|             159409.0|             1|\n",
      "|    S0010|  I00191|Cliff Builders Pr...|       1368.0|          17|             159409.0|             1|\n",
      "|    S0010|  I00181|Reese's Peanutbut...|       1352.0|          18|             159409.0|             1|\n",
      "|    S0010|  I00081|Tejava Unsweetene...|       1334.0|          19|             159409.0|             1|\n",
      "|    S0010|  I00115|K Cups Daily Chef...|       1325.0|          20|             159409.0|             1|\n",
      "+---------+--------+--------------------+-------------+------------+---------------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Keep only the relevant columns from each DataFrame\n",
    "factDF = factDF.select(\"item_key\", \"store_key\", \"total_price\")\n",
    "itemDF = itemDF.select(\"item_key\", \"item_name\")\n",
    "storeDF = storeDF.select(\"store_key\")\n",
    "\n",
    "# Combine fact table with item and store dimensions\n",
    "joinedDF = factDF.join(itemDF, \"item_key\").join(storeDF, \"store_key\")\n",
    "\n",
    "# Calculate total sales for each product in each store\n",
    "storeProductSalesDF = joinedDF.groupBy(\"store_key\", \"item_key\") \\\n",
    "    .agg(_sum(\"total_price\").alias(\"product_sales\"))\n",
    "\n",
    "# Total sales for each store\n",
    "storeTotalSalesDF = storeProductSalesDF.groupBy(\"store_key\") \\\n",
    "    .agg(_sum(\"product_sales\").alias(\"store_total_sales\"))\n",
    "\n",
    "# Rank stores by their total sales\n",
    "storeRankWindow = Window.orderBy(col(\"store_total_sales\").desc())\n",
    "storeTotalSalesDF = storeTotalSalesDF.withColumn(\"store_rank\", dense_rank().over(storeRankWindow))\n",
    "\n",
    "# Rank products within each store based on their sales\n",
    "productRankWindow = Window.partitionBy(\"store_key\").orderBy(col(\"product_sales\").desc())\n",
    "storeProductSalesDF = storeProductSalesDF.withColumn(\"product_rank\", dense_rank().over(productRankWindow))\n",
    "\n",
    "# Exclude products with zero sales\n",
    "storeProductSalesDF = storeProductSalesDF.where(col(\"product_sales\") > 0)\n",
    "\n",
    "# Select the top 100 stores by total sales (rank)\n",
    "top100StoresDF = storeTotalSalesDF.where(col(\"store_rank\") <= 100) \\\n",
    "    .withColumnRenamed(\"store_total_sales\", \"top_store_total_sales\") \\\n",
    "    .withColumnRenamed(\"store_rank\", \"top_store_rank\")\n",
    "\n",
    "# Join product details for the top 100 stores\n",
    "finalDF = storeProductSalesDF.join(top100StoresDF, \"store_key\")\n",
    "\n",
    "finalDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7926c88d-f6a6-47db-826a-40dc22d6ab12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to BigQuery\n",
    "spark.conf.set('temporaryGcsBucket', temp_bucket)\n",
    "\n",
    "finalDF.write.format('bigquery') \\\n",
    "    .option('table', f'{project_id}.a2.product_sales_by_store') \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .save()\n",
    "\n",
    "# Stop Spark Session\n",
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
